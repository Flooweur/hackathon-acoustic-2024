{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of centroids (labels) = (1000, 2)\n",
      "Shape of deconvoled (features)= (1000, 4, 667200)\n"
     ]
    }
   ],
   "source": [
    "# Load the RIR data and labels \n",
    "human_rir_data = np.load('/home/onyxia/work/hackathon-acoustic-2024/data/LivingRoom_preprocessed_hack/Human1/deconvoled_trim.npy') \n",
    "human_rir_labels = np.load('/home/onyxia/work/hackathon-acoustic-2024/data/LivingRoom_preprocessed_hack/Human1/centroid.npy')\n",
    "print(f\"Shape of centroids (labels) = {human_rir_labels.shape}\")\n",
    "print(f\"Shape of deconvoled (features)= {human_rir_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4)\n",
      "RMS of RIR = [0.00052505 0.00050232 0.00070836 0.00042991]\n",
      "RMS of RIR = [0.00052084 0.00049965 0.00070709 0.0004291 ]\n",
      "RMS of RIR = [0.00052198 0.00049891 0.00070534 0.00042922]\n"
     ]
    }
   ],
   "source": [
    "def rms(y): # https://stackoverflow.com/questions/40963659/root-mean-square-of-a-function-in-python\n",
    "    return np.sqrt(np.mean(y**2))\n",
    "\n",
    "rms_levels = np.apply_along_axis(rms, axis=2, arr=human_rir_data)\n",
    "# Check the shape of the resulting array, just to be sure\n",
    "print(rms_levels.shape)\n",
    "for i in range(3):\n",
    "    print(f\"RMS of RIR = {rms_levels[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4, 2)\n",
      "RMS of RIR = [[7.4201950e-04 2.7637041e-05]\n",
      " [7.1022433e-04 1.5197927e-05]\n",
      " [1.0016420e-03 1.5790252e-05]\n",
      " [6.0776662e-04 1.6449338e-05]]\n",
      "RMS of RIR = [[7.36104092e-04 2.63096808e-05]\n",
      " [7.06433610e-04 1.57759641e-05]\n",
      " [9.99839045e-04 1.67664130e-05]\n",
      " [6.06665155e-04 1.44089845e-05]]\n",
      "RMS of RIR = [[7.3734019e-04 3.5381654e-05]\n",
      " [7.0538954e-04 1.5878721e-05]\n",
      " [9.9737174e-04 1.5951553e-05]\n",
      " [6.0618843e-04 3.1575102e-05]]\n"
     ]
    }
   ],
   "source": [
    "def rms_over_n_partitions(y, n):\n",
    "    array_len = len(y)\n",
    "    # Compute the length of each fraction\n",
    "    fraction_len = array_len // n\n",
    "    # Compute RMS for each fraction of the array\n",
    "    rms_fractions = []\n",
    "    for i in range(n):\n",
    "        start_index = i * fraction_len\n",
    "        end_index = (i + 1) * fraction_len if i < n - 1 else array_len\n",
    "        rms_fraction = np.sqrt(np.mean(y[start_index:end_index]**2))\n",
    "        rms_fractions.append(rms_fraction)\n",
    "    # Concatenate the results horizontally\n",
    "    return np.hstack(rms_fractions)\n",
    "\n",
    "# Example usage:\n",
    "n = 2  # Number of fractions, change this number\n",
    "# Calculate RMS levels for each sample along the last axis\n",
    "rms_levels = np.apply_along_axis(rms_over_n_partitions, axis=2, arr=human_rir_data, n=n)\n",
    "# Check the shape of the resulting array\n",
    "print(rms_levels.shape)\n",
    "# Print some example values\n",
    "for i in range(3):\n",
    "    print(f\"RMS of RIR = {rms_levels[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using 'raw' datas\n",
    "If you use this cell, the whole data from dataset will be used for Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from first cell np.load('...../Human1/deconvoled_trim.npy')  \n",
    "features = human_rir_data  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using datas then extract feature using RMS\n",
    "If you use this cell, the whole data from dataset will be used.\n",
    "Then the Root Mean Squared (RBS) formula will be applied to it.\n",
    "This will reduce the whole sampling to an unique scalar.\n",
    "\n",
    "By default, the number of values kept is set to 2. \n",
    "Please change this number in the cell just above, where \"rms_over_n_partitions\" function is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the RMS levels\n",
    "features = (rms_levels - np.mean(rms_levels, axis=0)) / np.std(rms_levels, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using datas with PCA\n",
    "If you use this cell, the whole data from dataset will be used.\n",
    "Then, a PCA Linear dimensionality reduction using Singular Value Decomposition of the data to a lower dimensional space will be applied.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = human_rir_data.reshape((1000,-1)) # 1000 is the N_datapoints; 104 for human2 dataset\n",
    "pca = PCA(n_components=10)\n",
    "features = pca.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a set of features, and a set of labels (loaded in the first cells).\n",
    "We can then use the Linear Regression model to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is fitting for x coordinates\n",
      "model is fitting for y coordinates\n",
      "Randomly Selected Predictions:\n",
      "Index 169: True Position = [-3742.64284046 -2567.70120661], Predicted Position = [-2881.94  -2179.181]\n",
      "Index 141: True Position = [-2635.02066166 -1298.19706888], Predicted Position = [-2595.5605 -2224.788 ]\n",
      "Index 185: True Position = [-150.49529301  762.35079477], Predicted Position = [-1622.9569  -440.9784]\n",
      "\n",
      "Mean localization error: 1365.305 mm\n"
     ]
    }
   ],
   "source": [
    "labels = human_rir_labels\n",
    "\n",
    "# Classical approach of a Linear Regression model.\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the RMS levels data to have the correct shape\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Train a linear regression model for each coordinate separately \n",
    "regressor_x = LinearRegression()\n",
    "print(\"model is fitting for x coordinates\")\n",
    "regressor_x.fit(X_train_reshaped, y_train[:, 0])  # Train for x-coordinate\n",
    "\n",
    "regressor_y = LinearRegression()\n",
    "print(\"model is fitting for y coordinates\")\n",
    "regressor_y.fit(X_train_reshaped, y_train[:, 1])  # Train for y-coordinate\n",
    "\n",
    "# Reshape X_test to have only two dimensions\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred_x = regressor_x.predict(X_test_reshaped)\n",
    "y_pred_y = regressor_y.predict(X_test_reshaped)\n",
    "\n",
    "\n",
    "# Select 10 random indices from the test set\n",
    "random_indices = random.sample(range(len(y_test)), 3)\n",
    "\n",
    "# Combine x and y predictions into coordinates\n",
    "y_pred = np.column_stack((y_pred_x, y_pred_y))\n",
    "\n",
    "# Print the predicted and true positions for the selected indices\n",
    "print(\"Randomly Selected Predictions:\")\n",
    "for idx in random_indices:\n",
    "    true_pos = y_test[idx]\n",
    "    pred_pos = y_pred[idx]\n",
    "    print(f\"Index {idx}: True Position = {true_pos}, Predicted Position = {pred_pos}\")\n",
    "\n",
    "# Calculate Euclidean distance between predicted and actual coordinates\n",
    "errors = np.sqrt(np.sum((y_pred - y_test)**2, axis=1))\n",
    "mean_error = np.mean(errors)\n",
    "print(f'\\nMean localization error: {mean_error:.3f} mm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

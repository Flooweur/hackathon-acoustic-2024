{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic_height = 50.3125\n",
    "feet = 12\n",
    "y_tile = 23.5\n",
    "x_tile = 11 +7/8\n",
    "\n",
    "camera_origin_location = np.array([-6*x_tile-5.75, -y_tile, 45+13/16])*25.4\n",
    "\n",
    "mic_1 = np.array([-11*x_tile - 1, -5*y_tile - 6-3/8, mic_height]) * 25.4 \n",
    "mic_4= np.array([-11*x_tile + 1.25 + 1/16, 2.5*y_tile+3.75, mic_height]) * 25.4\n",
    "mic_6 = np.array([5+3/8, 2+1/8, mic_height]) * 25.4\n",
    "mic_9 = np.array([-3, -6*y_tile - 0.5, mic_height]) * 25.4\n",
    "\n",
    "\n",
    "mic_xyzs = np.stack((mic_1,mic_4, mic_6, mic_9),axis=0)\n",
    "\n",
    "SPEAKER_BOTTOM_RIGHT_Y = (1200.15 + 1196.975 + 1206.5)/ 3\n",
    "SPEAKER_BOTTOM_RIGHT_X = (88.9 + 107.95 + 101.6) / 3\n",
    "SPEAKER_BOTTOM_LEFT_Y = (1327.15 + 1311.55712764 + 1317.625) / 3\n",
    "SPEAKER_BOTTOM_LEFT_X = - 76.98583188\n",
    "\n",
    "speaker_xyz_bottom_right = np.array([SPEAKER_BOTTOM_RIGHT_X, SPEAKER_BOTTOM_RIGHT_Y, 44.5*25.4])\n",
    "speaker_xyz_bottom_left = np.array([SPEAKER_BOTTOM_LEFT_X, SPEAKER_BOTTOM_LEFT_Y, 44.5*25.4])\n",
    "speaker_xyz_top_right = np.array([SPEAKER_BOTTOM_RIGHT_X, SPEAKER_BOTTOM_RIGHT_Y, (44.5+17)*25.4])\n",
    "speaker_xyz_top_left = np.array([SPEAKER_BOTTOM_LEFT_X, SPEAKER_BOTTOM_LEFT_Y, (44.5+17)*25.4])\n",
    "speaker_xyz = (speaker_xyz_bottom_right+speaker_xyz_bottom_left+speaker_xyz_top_right+speaker_xyz_top_left)/4\n",
    "\n",
    "\n",
    "walls = None\n",
    "x_min = - 4000\n",
    "x_max = 500\n",
    "y_min = -4000\n",
    "y_max = 2000\n",
    "\n",
    "\n",
    "## affichier la disposition des microphones.\n",
    "for idx, mic in enumerate(mic_xyzs):\n",
    "    plt.scatter(mic[0], mic[1], label=f'mic {idx+1}')\n",
    "\n",
    "plt.title(\"RÃ©partition des micros\")\n",
    "plt.xlim([-5500, 1000])\n",
    "plt.ylim([-4500, 2500])\n",
    "plt.legend(loc=\"lower left\", title=\"microphone\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"/home/onyxia/work/hackathon-acoustic-2024/data/LivingRoom_preprocessed_hack/Human1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Centroide : (1000, 2) \n"
     ]
    }
   ],
   "source": [
    "# Load centroid (humain xy positions)\n",
    "\n",
    "centroid = np.load(os.path.join(DATASET_PATH, 'centroid.npy'))\n",
    "print(f\"Shape Centroide : {centroid.shape} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape RIRs : (1000, 4, 667200) \n"
     ]
    }
   ],
   "source": [
    "RIRs = np.load(os.path.join(DATASET_PATH, \"deconvoled_trim.npy\"), mmap_mode='r')\n",
    "print(f\"Shape RIRs : {RIRs.shape} \")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
